**편향**이 크다 → 과소적합(underfitting), 예측이 정확한 값에서 멀리 벗어남
**분산**이 크다 → 과대적합(overfitting), 특성 샘플에 대한 예측의 일관성이 큼

좋은 모델이란 **편향과 분산이 모두 낮은** 모델이다.
→ 편향과 분산의 균형(bias-variance trade-off)

좋은 편향-분산 트레이드오프를 찾는 한 가지 방법은 **규제**를 사용하여 모델의 복잡도를 조정하는 것이다.

**규제(regularization)**는 공선성(특성 간의 높은 상관관계)을 다루거나 데이터에서 잡음을 제거하여 과대적합을 방지할 수 있는 매우 유용한 방법이다.

규제는 과도한 파라미터(가중치) 값을 제한하기 위해 추가적인 정보를 주입하는 개념이다.

가장 널리 사용하는 **L2 규제**는 다음과 같은 형태이다.

$$
\frac{\lambda}{2n} ||\mathbf{w}||^2 = \frac {\lambda}{2n} \sum_{j=1}^m w_j^2
$$

여기서 $\lambda$ 는 규제 **하이퍼파라미터**이다.